{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import defaultdict\n",
    "#from gym.envs.registration import register\n",
    "#register(\n",
    "#    id='FrozenLakeNotSlippery-v0',\n",
    "#    entry_point='gym.envs.toy_text:FrozenLakeEnv',\n",
    "#    kwargs={'map_name' : '4x4', 'is_slippery': False},\n",
    "#    max_episode_steps=100,\n",
    "#    reward_threshold=0.78, # optimum = .8196\n",
    "#)\n",
    "#env = gym.make('FrozenLakeNotSlippery-v0')\n",
    "env = gym.make('FrozenLake-v0')\n",
    "#env = gym.make('FrozenLake8x8-v0')\n",
    "#env = gym.make('Taxi-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_episode(Q,max_steps = 1000, epsilon =0.2):\n",
    "    episode = []\n",
    "    total_reward = []\n",
    "    state = env.reset()\n",
    "    for step in range(max_steps):\n",
    "        dice = random.random()\n",
    "        if dice < (epsilon):\n",
    "            action = env.action_space.sample()\n",
    "        else:\n",
    "            action = np.argmax(Q[state])\n",
    "        next_state, reward, done, info = env.step(action)\n",
    "        episode.append((state, action))\n",
    "        total_reward.append(reward)\n",
    "        state = next_state\n",
    "        if done:\n",
    "            break\n",
    "    return episode, total_reward\n",
    "\n",
    "def sample_play(Q):\n",
    "    done = False\n",
    "    state = env.reset()\n",
    "    total_reward = 0\n",
    "    while done == False:\n",
    "        env.render()\n",
    "        state, reward, done, info = env.step(np.argmax(Q[state]))\n",
    "        total_reward += reward\n",
    "    return total_reward\n",
    "\n",
    "def monte_carlo_control(first_visit = False,epsilon = 0.2, n_episodes = 1000000):\n",
    "    Q = np.zeros((env.env.nS,env.env.nA))\n",
    "    total_count = np.zeros((env.env.nS,env.env.nA))\n",
    "    for x in range(n_episodes):\n",
    "        episode, list_reward = play_episode(Q)\n",
    "        for state, action in episode:\n",
    "            total_count[state,action] += 1\n",
    "            if first_visit:\n",
    "                for i,get_episode in enumerate(episode):\n",
    "                    if get_episode[0] == state and get_episode[1] == action:\n",
    "                        first_idx = i\n",
    "                        break\n",
    "                total_reward = sum(list_reward[first_idx:])\n",
    "            else:\n",
    "                total_reward = sum(list_reward)\n",
    "            alpha = 1.0 / total_count[state, action]\n",
    "            Q[state, action] += alpha * (total_reward - Q[state, action])\n",
    "        if x%10000 == 0:\n",
    "            acc = play(Q)\n",
    "            print(acc)\n",
    "    return Q\n",
    "\n",
    "def play(Q,n_plays = 10000, max_steps = 1000, gamma = 1.0):\n",
    "    total_reward = 0\n",
    "    for x in range(n_plays):\n",
    "        state = env.reset()\n",
    "        for step in range(max_steps):\n",
    "            state, reward, done, info = env.step(np.argmax(Q[state]))\n",
    "            total_reward += (gamma ** step) * reward\n",
    "            if done:\n",
    "                break\n",
    "    return total_reward/n_plays\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.6075\n",
      "0.7047\n",
      "0.7418\n",
      "0.7286\n",
      "0.7197\n",
      "0.7269\n",
      "0.7332\n",
      "0.7284\n",
      "0.7309\n",
      "0.7259\n",
      "0.7247\n",
      "0.7324\n",
      "0.7333\n",
      "0.7267\n",
      "0.7354\n",
      "0.7352\n",
      "0.7329\n",
      "0.734\n",
      "0.7339\n",
      "0.7313\n",
      "0.7232\n",
      "0.7302\n",
      "0.7308\n",
      "0.7266\n",
      "0.7308\n",
      "0.7281\n",
      "0.7296\n",
      "0.73\n",
      "0.7298\n",
      "0.7266\n",
      "0.7245\n",
      "0.7304\n",
      "0.7227\n",
      "0.7285\n",
      "0.7201\n",
      "0.7363\n",
      "0.7309\n",
      "0.7332\n",
      "0.7262\n",
      "0.7334\n",
      "0.7388\n",
      "0.7269\n",
      "0.7308\n",
      "0.7283\n",
      "0.7232\n",
      "0.733\n",
      "0.7297\n",
      "0.73\n",
      "0.7266\n",
      "0.7335\n",
      "0.7276\n",
      "0.7266\n",
      "0.7341\n",
      "0.7272\n",
      "0.7276\n",
      "0.7236\n",
      "0.7277\n",
      "0.7309\n",
      "0.7333\n",
      "0.7253\n",
      "0.7291\n",
      "0.7325\n",
      "0.7339\n",
      "0.7302\n",
      "0.7271\n",
      "0.726\n",
      "0.735\n",
      "0.7223\n",
      "0.7291\n",
      "0.7243\n",
      "0.7269\n",
      "0.7285\n",
      "0.734\n",
      "0.7247\n",
      "0.7349\n",
      "0.732\n",
      "0.7261\n",
      "0.7222\n",
      "0.7225\n",
      "0.73\n",
      "0.7283\n",
      "0.7278\n",
      "0.7291\n",
      "0.7357\n",
      "0.7277\n",
      "0.737\n",
      "0.7315\n",
      "0.7281\n",
      "0.7327\n",
      "0.7285\n",
      "0.7263\n",
      "0.7314\n",
      "0.7288\n",
      "0.7322\n",
      "0.7282\n",
      "0.7274\n",
      "0.7318\n",
      "0.7371\n",
      "0.7355\n",
      "\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "SFFF\n",
      "FHFH\n",
      "\u001b[41mF\u001b[0mFFH\n",
      "HFFG\n",
      "  (Up)\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "SFFF\n",
      "FHFH\n",
      "\u001b[41mF\u001b[0mFFH\n",
      "HFFG\n",
      "  (Up)\n",
      "SFFF\n",
      "FHFH\n",
      "\u001b[41mF\u001b[0mFFH\n",
      "HFFG\n",
      "  (Up)\n",
      "SFFF\n",
      "FHFH\n",
      "F\u001b[41mF\u001b[0mFH\n",
      "HFFG\n",
      "  (Down)\n",
      "SFFF\n",
      "FHFH\n",
      "FF\u001b[41mF\u001b[0mH\n",
      "HFFG\n",
      "  (Left)\n",
      "SFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HF\u001b[41mF\u001b[0mG\n",
      "  (Down)\n",
      "SFFF\n",
      "FHFH\n",
      "FFFH\n",
      "H\u001b[41mF\u001b[0mFG\n",
      "  (Right)\n",
      "SFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HF\u001b[41mF\u001b[0mG\n"
     ]
    }
   ],
   "source": [
    "Q = monte_carlo_control(first_visit=False)\n",
    "sample_play(Q)\n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow-GPU",
   "language": "python",
   "name": "tensorflow-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
